# Evaluating Recommendation Systems

En este texto, de los autores Shani y Gunawardana, se explica el proceso general para evaluar sistemas recomendadores. A diferencia de los *papers* que hemos leído, este es en realidad un *handbook* con el que se busca enseñar y clarificar conceptos, más que publicar una nueva idea o algoritmo.

Primero se discuten tres diferentes tipos de experimentos; *offline*, *user studies* y *online*. El *offline*, al ser más barato, se usa como filtro para luego experimentar con los otros métodos y que no resulte tan cara su implementación. Luego está el *user-studies*, en el que se busca experimentar con posibles usuarios de una manera más presencial, añadiendo entrevistas o cuestionarios. Finalmente, está el experimento *online*, el cual suele funcionar con una interfaz acorde a cómo será realmente el software, para obtener también resultados de conformidad del usuario con el uso total de la aplicación. La calidad de estas tres explicaciones es alta, ya que dividen cada una en secciones con sus diferentes formas posibles de implementación, en donde dan ejemplos y muestran claramente sus ventajas y desventajas.

En particular, no había escuchado hablar de los *user-studies* para sistemas recomendadores y me parece que son verdaderamente útiles para obtener resultados cualitativos, a diferencia de los otros experimentos vistos en clases. Esto es muy importante para interpretar el por qué de ciertos resultados cuantitativos, lo que podría nutrir de forma muy positiva a un análisis.

Más adelante, dentro de las métricas de exactitud, se entrega una breve y concisa explicación de RMSE y MAE, que me ayudó a terminar de comprender estas populares métricas de error y por qué difieren entre sí. Específicamente, no me había quedado muy claro que RMSE penalizaba el error de forma más drástica que MAE y para qué tipos de sistemas cada uno arrojaría mejores resultados.

Se explican tmabién en profundiad conceptos como *confidence*, *trust*, *novelty* o *serendipity*, que corresponden a propiedades que uno ve en prácticamente todos los *papers* que lee sobre sistemas recomendadores, pero no necesariamente sabe a qué se refieren exactamente. Además de explicarlas, sugieren, para cada una de ellas, un experimento con el que la propiedad puede ser medida en un sistema recomendador. También mencionan propiedades menos técnicas pero altamente importantes, como *privacy*, *adaptivity* o *scalability*, las que describen y ejemplifican de una manera bastante pedagógica.

Si bien en el texto no se presenta una idea original en cuanto a la aplicación o evaluación de sistemas recomendadores, se repasan conceptos cruciales para comprender desventajas y ventajas de usar cierto método o métrica en casos específicos. El *handbook*, finalmente, funciona como una guía introductoria a los sistemas recomendadores, que puede servir para indicar por dónde es conveniente seguir investigando si alguien se encuentra interesado por un aspecto en especial.